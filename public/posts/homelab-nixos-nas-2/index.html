<!doctype html><html lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=你在世纪大道东门 name=description><link href=/main.css rel=stylesheet><script src=/js/theme-toggle.js></script><script>document.documentElement.classList.toggle('dark-mode', 
            localStorage.getItem('theme') === 'dark' || 
            (!localStorage.getItem('theme') && window.matchMedia('(prefers-color-scheme: dark)').matches)
        );</script><title>世纪大道</title><link href=/favicon.ico rel=icon type=image/x-icon><script defer src=/js/posts/copy2clipboard.js></script><body><header><nav><a href=https://blog.0pt.icu/atom.xml>/rss</a><a href=https://blog.0pt.icu>/home</a><a href=https://blog.0pt.icu/posts>/posts</a><a href=https://blog.0pt.icu/links>/links</a><a href=https://blog.0pt.icu/about>/about</a></nav><div class=theme-toggle-container><input aria-label=theme-toggle class=checkbox id=checkbox type=checkbox><label class=checkbox-label for=checkbox><span class=ball></span></label></div></header><div><h1>My NixOS NAS🧊 (2)</h1><span>2025-10-17</span><div class=toc><ul><li><a href=https://blog.0pt.icu/posts/homelab-nixos-nas-2/#my-nixos-nasice-cube-2>My NixOS NAS🧊 (2)</a> <ul><li><a href=https://blog.0pt.icu/posts/homelab-nixos-nas-2/#magic-wand-introduction>🪄 Introduction</a><li><a href=https://blog.0pt.icu/posts/homelab-nixos-nas-2/#construction-site-rebuild>🏗️ Rebuild</a></ul></ul></div><div class=post-content><h1 id=my-nixos-nasice-cube-2>My NixOS NAS🧊 (2)</h1><p>2025-10-17<p>You can find <a href=https://github.com/antipeth/atplab>my configuration here</a>. You can find <a href=https://blog.0pt.icu/posts/homelab-nixos-nas/>my previous article here</a>.<hr><h2 id=magic-wand-introduction>🪄 Introduction</h2><p>Back in <strong>March</strong>, I built my NAS using <strong>NixOS</strong>, and it’s been running <strong>rock-solid</strong> ever since 💪. However, this August I made some big hardware and backup changes. For some reason, I bought an extra <strong>32 GB RAM stick</strong>, bringing my NAS’s total memory to <strong>40 GB</strong> 🧠.<p>I also purchased a <strong>Western Digital HC620 zoned mechanical drive (SMR)</strong> — <strong>14 TB</strong> — to store my static media files 🎬. I couldn’t format this drive using <code>nixos disko</code>, but <code>mkfs</code> worked perfectly, and mounting it with <code>filesystem</code> caused no conflicts at all.<table><thead><tr><th>Name<th>Content<tbody><tr><td>Motherboard<td>GIGABYTE A520i Dash<tr><td>CPU<td>R5 5600G<tr><td>Memory<td>8 GB + 32 GB DDR4<tr><td>SSD<td>512 GB NVMe PCIe 3 × 4<tr><td>HDD<td>2 × 1 TB<tr><td>HDD<td>14 TB</table><p>Because my <strong>dorm cuts power every night</strong> 🔌, I can’t keep the mechanical drives constantly connected — it would wear them out too fast. So I turned them into <strong>cold backups</strong>, doing a scheduled sync <strong>once per month</strong> 🧊. Of course, my local data is still <strong>backed up to S3 daily</strong> ☁️.<p>I also bought a <strong>VPS</strong> to host my online services 🌐.<p>So, it was time to <strong>rebuild my NixOS NAS</strong> — transforming it into a proper <strong>NixOS-based homelab environment</strong> 🧰.<hr><h2 id=construction-site-rebuild>🏗️ Rebuild</h2><h3 id=repeat-replacing-clan-with-nixos-rebuild>🔁 Replacing <code>clan</code> with <code>nixos-rebuild</code></h3><p>In my previous article, I highly recommended the <code>clan</code> tool. Unfortunately… I’ve decided to drop it 😅.<ol><li>Since March, <code>clan</code> has had major updates — mostly around the <code>inventory</code> system. But I don’t really need that; I want my setup to stay <strong>as close to pure NixOS</strong> as possible.<li>One big reason I originally used <code>clan</code> was for <strong>multi-host deployment</strong> and management. But after an update, I found that when deploying just one machine, <code>clan</code> still <strong>checks the configuration of all machines</strong> — which conflicts with my <strong>SOPS-encrypted values and secrets</strong> approach 🔐.<li>Also, even though I configure my network through <code>networking</code> and <em>not</em> <code>systemd-network</code>, <code>clan</code> still automatically enables it 🤔. This isn’t a big issue locally or on some VPSs, but on certain ones it <strong>completely breaks IPv6</strong> 💥.</ol><p><code>clan</code> is a great project — just not the right fit for me anymore. So I switched back to the good old <strong><code>nixos-rebuild</code></strong> 🧱.<p>For multi-machine deployment, I now use a <strong>Justfile</strong> with scripts that dynamically insert the hostname using <code>seq</code>, and I simply <strong>avoid committing these transient changes</strong> to Git 🧹.<hr><h3 id=lock-using-nixos-sops>🔒 Using <code>nixos-sops</code></h3><p>Previously, I used the SOPS integration built into <code>clan</code>. Now I use <strong>SOPS directly</strong>, with a cleaner directory structure for encryption 🔧.<p>Let’s look at what changed 👇<p><strong>Before (with <code>clan</code>):</strong><ul><li>Secrets were stored in <code>sops/secrets/</code>.<li>Encrypted values or strings were stored in <code>sops/eval/&LTmachine-name>/</code>.</ul><p><strong>After the rebuild:</strong><ul><li>Secrets are now stored in <code>machines/&LTmachine-name>/secrets/</code>.<li>Encrypted values or strings are now stored in <code>machines/&LTmachine-name>/values/</code>.</ul><p>You can find my related article about SOPS encryption here. 👇<ul><li><a href=https://blog.0pt.icu/posts/nixos-sops-nix-quick-start-guide/>Sops-nix Quick Start Guide</a><li><a href=https://blog.0pt.icu/posts/nixos-using-sops-to-encrypt-nix-values/>Using SOPS to Encrypt Nix Values</a></ul><p>This makes import paths in Nix much simpler ✨.<hr><h3 id=closed-lock-with-key-switching-from-acme-certificates-to-self-signed-certificates>🔐 Switching from ACME Certificates to Self-Signed Certificates</h3><p>At first, my NixOS NAS used <strong>ACME</strong> certificates, integrated nicely with Nginx. But once I added a VPS, I needed a way to <strong>distribute certificates</strong> among machines 📨.<p>Here was my initial idea 💭:<ol><li>The VPS runs a <strong>Headscale</strong> server, and both cloud and local machines join the Headscale network 🕸️.<li>The VPS obtains certificates via <strong>ACME</strong>.<li>The VPS uses <strong>rclone</strong> to encrypt and store the certs in another local directory.<li>Nginx on the VPS serves an <strong>HTTPS static file server</strong> (inside the Headscale network, using the domain generated by <code>magic_dns</code>) 🌐.<li>Other machines use <strong>rclone’s HTTP backend</strong> to periodically pull and decrypt the certs locally 🔁.</ol><p>But when I actually started setting it up… I got lazy 😆. So I just went with <strong>self-signed certificates</strong> — zero maintenance required.<p>For local services, that’s perfectly fine ✅. For cloud services, combining <strong>self-signed certs + CDN</strong> is totally enough for a personal <strong>homelab</strong> setup 🏠.<hr><h3 id=jigsaw-other-improvements>🧩 Other Improvements</h3><ul><li>☁️ Added Headscale in the cloud to manage all devices within a private network.<li>🗂️ Reorganized the <strong>directory structure</strong>.<li>🌀 Used a <strong>recursive import function</strong> (<code>lib.filesystem.listFilesRecursive</code>) to simplify Nix code.<li>📁 All example service modules are now stored under <code>machines/example/modules/</code>.</ul></div></div><script type=module>import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
            mermaid.initialize({ theme: 'neutral',});</script>